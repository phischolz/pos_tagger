% !TEX root = ../thesis-example.tex
%
% Copypastas:
% "Text": \glqq Text\grqq{}
\chapter{Allgemein}
\label{sec:general}

Um einheitliche Verarbeitung und Vergleichbarkeit zu ermöglichen, werden die Tags in \textit{Tagsets} definiert, wie zum Beispiel dem des Penn-Treebank-Projekts \linebreak \cite{Web:PennBank:2003}. \newline
Betrachtet man das Wort \glqq like \grqq{} aus dem einleitenden Beispiel \glqq I like the blue House.\grqq, dann fällt auf, dass es alternativ zum Verb \glqq mögen\grqq{} auch als Präposition \glqq wie\grqq{} interpretiert werden könnte, auch wenn der Satz dann keinen Sinn mehr ergibt. Diese Uneindeutigkeit (\textit{Ambiguität}) ist das zentrale zu lösende Problem für POS-Tagger  \cite{Smith:2011}; Im Gegensatz zum Menschen kann ein Algorithmus Ambiguitäten nicht intuitiv auflösen, sondern muss auf statistische, rechnerische und linguistische Methoden sowie Wissen aus diesen Teilbereichen zurückgreifen. \newline
%Goldstandards und Präzision

\section{Tagging-Ansätze}
\label{sec:general:types}
% "stumpf": nachschlagen und raten
% statistisch (ohne und mit kontext)
% regelbasiert
% lernend

\section{Probleme und Ziele}
\label{sec:general:goals}

Da Tagging-Algorithmen sowohl nicht fehlerfrei arbeiten als auch in ihrem Ergebnisformat voneinander - und insbesondere von Goldstandards - abweichen, entstehen Unsicherheiten beim Arbeiten mit solchen Informationen. Welche Probleme besonders dominant sind und welche Zielsetzungen für das Projekt sich daraus ergeben, wird in den folgenden Abschnitten ausführlicher behandelt.

\subsection{Tokenization-Unterschiede}
\label{sec:general:goals:tok}

Ein wichtiger Schritt zur Vorverarbeitung von Text ist es, ihn in \textit{Tokens} zu zerlegen. Ein Token ist ein Abschnitt, zu dem ein Tag gehört, typischerweise einzelne Wörter oder Satzzeichen. Formal wird aus dem zusammenhängenden Wort beziehungsweise Text \textit{w} eine Menge \textit{M} von \textit{n} Teilwörtern c\textsubscript{i} 
 \[  M = \{ c_1 , c_2 , ... , c_n \} \] 
 generiert. POS-Tagger wie der von NLP4J :NC und der Stanford University :NC übernehmen diese Zerlegung selbst. Nehmen wir nun an, \textit{M} wäre die Zerlegung von \textit{w} in einem Goldstandard, und ein Tagger produziert ein Ergebnis mit der Zerlegung:
 \[  M_{tag} = \{ d_1 , d_2 , ... , d_m \} \]
Hierbei sind \textit{d\textsubscript{i}} wieder Teilworte und \textit{m} die Anzahl dieser. Spätestens wenn nun $n \neq m$ gilt, wird klar, dass \textit{M} und \textit{M\textsubscript{tag}} nicht mehr einfach iterativ verglichen werden können, da ab der Stelle \textit{p}, wo der Text unterschiedlich geteilt wurde, $ c_i \neq d_i $ sein kann, wobei $ (p \leq i \leq min\{ n, m \}) $. Es ist sogar nicht auszuschließen, dass solche Fehler bereits vorher passieren, obwohl weiterhin $n = m$ gilt.
\newline
Eines der Ziele bei der Implementierung ist also, den Vergleich von zwei Token-Mengen robust gegen solche Fehler zu machen.
%\section{Related Work Section 2}
%\label{sec:related:sec2}
%
%
%\section{Related Work Section 3}
%\label{sec:related:sec3}
%
%
%
%\section{Conclusion}
%\label{sec:related:conclusion}


